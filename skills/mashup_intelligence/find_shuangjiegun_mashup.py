import asyncio
import sys
import json
from pathlib import Path

BASE_DIR = Path("d:/anti")
sys.path.insert(0, str(BASE_DIR))
sys.path.insert(0, str(BASE_DIR / "core" / "rekordbox-mcp"))

from rekordbox_mcp.database import RekordboxDatabase
from skills.mashup_intelligence.scripts.core import MashupIntelligence
from core.cache_manager import load_cache

# å¼ºåˆ¶ UTF-8 è¾“å‡º
if sys.stdout.encoding.lower() != 'utf-8':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

async def main():
    db = RekordboxDatabase()
    await db.connect()
    
    # 1. å¯»æ‰¾â€œåŒæˆªæ£â€
    found_tracks = await db.search_tracks_by_filename("åŒæˆªæ£")
    if not found_tracks:
        all_tracks = await db.get_most_played_tracks(limit=2000)
        found_tracks = [t for t in all_tracks if "åŒæˆªæ£" in t.title or "åŒæ°ä¼¦" in str(t.artist)]
        
    if not found_tracks:
        print("âŒ æ‰¾ä¸åˆ°æ›²ç›®ï¼šåŒæˆªæ£")
        await db.disconnect()
        return

    target_track = found_tracks[0]
    target_path = target_track.file_path.replace('\\', '/')
    print(f"ğŸ¯ ç›®æ ‡æ›²ç›®: {target_track.title} - {target_track.artist} (BPM: {target_track.bpm}, Key: {target_track.key})")

    # 2. åŠ è½½å…¨åº“åˆ†ææ•°æ®
    cache = load_cache()
    path_map = {v.get('file_path', '').replace('\\', '/'): v for v in cache.values()}
    
    def get_analysis_for_track(t):
        path = t.file_path.replace('\\', '/')
        entry = path_map.get(path)
        if not entry:
            return {
                'bpm': t.bpm,
                'key': t.key,
                'vocal_ratio': 0.5,
                'energy': t.rating * 20 if t.rating else 50,
                'file_path': t.file_path,
                'tags': []
            }
        if 'analysis' in entry:
            return entry['analysis']
        return entry

    target_analysis = {
        'track_info': {'title': target_track.title, 'artist': target_track.artist, 'file_path': target_track.file_path},
        'analysis': get_analysis_for_track(target_track)
    }

    # 3. æ‰«æåº“ä¸­æ‰€æœ‰éŸ³è½¨
    all_lib_tracks = await db.get_most_played_tracks(limit=1500)
    
    mi = MashupIntelligence()
    matches = []
    
    print(f"ğŸ” æ­£åœ¨æ‰«ææ›²åº“å¯»æ‰¾å®Œç¾å¥‘åˆç‚¹ (V5.3 å¼•æ“, é˜ˆå€¼: 40)...")
    for t in all_lib_tracks:
        if t.file_path == target_track.file_path:
            continue
            
        candidate_analysis = {
            'track_info': {'title': t.title, 'artist': t.artist, 'file_path': t.file_path},
            'analysis': get_analysis_for_track(t)
        }
        
        score, details = mi.calculate_mashup_score(target_analysis, candidate_analysis)
        
        if score >= 40:
            matches.append({
                'score': score,
                'details': details,
                'track': t,
                'analysis': candidate_analysis
            })

    matches.sort(key=lambda x: x['score'], reverse=True)

    report_path = Path("d:/anti/shuangjiegun_report.md")
    with open(report_path, "w", encoding="utf-8") as f:
        f.write("# åŒæˆªæ£ (Nunchucks) - Mashup ä¸“å®¶å¤ç›˜ (V5.3 å¼•æ“ç‰ˆ)\n\n")
        f.write(f"ğŸ¯ **ç›®æ ‡æ›²ç›®**: {target_track.title} - {target_track.artist}\n")
        f.write(f"- BPM: {target_track.bpm} | Key: {target_track.key}\n\n")
        f.write("> [!NOTE]\n")
        f.write("> ã€ŠåŒæˆªæ£ã€‹å…·æœ‰æå¼ºçš„é‡‘å±/æ‘‡æ»šæ··åˆå˜»å“ˆç‰¹å¾ï¼ŒV5.3 å¼•æ“å¼ºåŒ–äº†å¯¹å…¶æ‰“å‡»ä¹è´¨æ„Ÿå’Œèƒ½é‡çˆ†å‘ç‚¹çš„æ•æ‰ã€‚\n\n")
        f.write("---\n\n")
        
        for i, m in enumerate(matches[:20]):
            t = m['track']
            f.write(f"### {i+1}. [{m['score']:.1f}] {t.title} - {t.artist}\n")
            f.write(f"**å¥‘åˆç»´åº¦**:\n")
            f.write(f"- æ•°å€¼å¥‘åˆåº¦: {m['details'].get('perceptual_speed', 'N/A')}\n")
            f.write(f"- è°ƒæ€§å…¼å®¹å¾—åˆ†: {m['details'].get('key', 'N/A')}\n")
            f.write(f"- å¾‹åŠ¨åŒæ­¥ (Groove): {m['details'].get('groove_style', 'N/A')}\n")
            
            if 'sampling_heritage' in m['details'] or 'cross_cultural' in m['details']:
                f.write(f"- **æ–‡åŒ– DNA**: {m['details'].get('sampling_heritage', '')} {m['details'].get('cross_cultural', '')}\n")
                
            f.write(f"- æ ¸å¿ƒæ¨¡å¼: {m['details'].get('mashup_pattern', 'è‡ªç”±ç»„åˆ')}\n\n")
            
            guide = mi.generate_unified_guide(target_analysis, m['analysis'], m['score'], m['details'])
            f.write(f"**ğŸ® [æœ€å¼ºå¤§è„‘] ä¸“å®¶å»ºè®®**:\n")
            for line in guide[1:]:
                f.write(f"> {line.replace('>', '').strip()}\n")
            f.write("\n---\n\n")

    print(f"âœ… æŠ¥å‘Šå·²ç”Ÿæˆè‡³: {report_path}")
    await db.disconnect()

if __name__ == "__main__":
    asyncio.run(main())
